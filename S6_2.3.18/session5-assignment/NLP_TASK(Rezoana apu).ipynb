{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this block to install dependencies [Remember to make the statement true]\n",
    "if 0 == 1:\n",
    "    !pip3 install pandas\n",
    "    !pip3 install tqdm\n",
    "    !pip3 install scikit-learn\n",
    "    !pip3 install gensim\n",
    "    !pip3 install spacy\n",
    "    !python3 -m spacy download en\n",
    "    !pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rezwana\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "DATA_LIMIT = 1000\n",
    "\n",
    "df = pd.read_csv('./imdb_master.csv', encoding='latin1')\n",
    "df_neg = df[df['label'] == 'neg']\n",
    "df_pos = df[df['label'] == 'pos']\n",
    "df = pd.concat((df_pos[:DATA_LIMIT], df_neg[:DATA_LIMIT]))\n",
    "df_test=pd.concat((df_pos[1000:1500], df_neg[1000:1500]))\n",
    "def process_text(input_string, return_string=False, stem=False):\n",
    "    text = nlp(u'' + input_string)\n",
    "    if stem == True:\n",
    "        text = [tok.lemma_ for tok in text if (tok.is_alpha and not tok.is_stop)]\n",
    "    else:\n",
    "        text = [tok.lower_ for tok in text if (tok.is_alpha and not tok.is_stop)]\n",
    "    if return_string == True:\n",
    "        return \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make this statement true to run from scratch [It takes time to process the text]\n",
    "if 1 == 0:\n",
    "    wordlist = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        wordlist.append(process_text(df['review'].iloc[i]))\n",
    "        \n",
    "    with open('vocabulary.txt', 'wb') as vocabulary:\n",
    "        pickle.dump(wordlist, vocabulary)\n",
    "    vocabulary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "wordlist = []\n",
    "with open('vocabulary.txt', 'rb') as vocabulary:\n",
    "    wordlist = pickle.load(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens - 5464\n"
     ]
    }
   ],
   "source": [
    "# Keeping track of frequency of a single token\n",
    "frequency = defaultdict(int)\n",
    "for text in wordlist:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "# Apply Threshold to limit the vocabulary size, discarding the tokens which appeard number of times below the threshold limit \n",
    "FREQ_THRESHOLD = 5\n",
    "\n",
    "thresholded_wordlist =  [[token for token in text if frequency[token] > FREQ_THRESHOLD]\n",
    "          for text in wordlist]\n",
    "\n",
    "# Create Dictionary based on the word list\n",
    "dictionary = Dictionary(thresholded_wordlist)\n",
    "\n",
    "# Number of tokens\n",
    "print(\"Number of Tokens - {}\".format(len(dictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(5464 unique tokens: ['able', 'admit', 'ben', 'character', 'comedy']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i.imgur.com/f1uzTDZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* From the screenshot you can see the implementation of word-cooccurance matrix, based on the tokens from the dictionary, build a word-cooccurance matrix yourself which is $X$. Documentation of gensim [https://radimrehurek.com/gensim/corpora/dictionary.html]\n",
    "* Apply SVD on $X$\n",
    "* Reduce Dimension \n",
    "\n",
    "![dimen_reduc](https://i.imgur.com/lezB870.png)\n",
    "\n",
    "* Here Richard is taking only top two dimensions of the vector $U$, recommended size is *50* for now.\n",
    "\n",
    "![dimen_reduc_u](https://i.imgur.com/TA2Bmsq.png)\n",
    "\n",
    "* Now we can get a fixed size vector for each word. \n",
    "\n",
    "* Try to plot something similar based on the given dataset. In class we will try to implement a logistic regression classifier that can classify positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_d=len(dictionary)\n",
    "X=np.zeros((len_d,len_d))\n",
    "la=np.linalg\n",
    "for sen in thresholded_wordlist:\n",
    "    idx=dictionary.doc2idx(sen)\n",
    "    for i in idx:\n",
    "        for j in idx:\n",
    "            X[i,j]=X[i,j]+1\n",
    "U,s,Vh = la.svd(X, full_matrices=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U_new=U[:,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5464, 50)\n"
     ]
    }
   ],
   "source": [
    "print(U_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5464, 5464)\n"
     ]
    }
   ],
   "source": [
    "print(Vh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n33e2p9waAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22b08182908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for i in [1, 140, 400, 750]:\n",
    "    plt.text(U[i,0], U[i,1], dictionary[i])\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    #how to plot this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sen2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-aa4fc1971015>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msen2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresholded_wordlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sen2vec' is not defined"
     ]
    }
   ],
   "source": [
    "sen2vec(thresholded_wordlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sen2vec(sen):\n",
    "    l=len(sen)\n",
    "    #X_train=np.zeros()\n",
    "#     print(l)\n",
    "    idx=dictionary.doc2idx(sen)\n",
    "#     print(idx)\n",
    "    vec=U_new[idx]\n",
    "#     print(vec)\n",
    "    total_sum=sum(vec) #feature wise sum (column)\n",
    "#     avg=total_sum/l\n",
    "#     print(total_sum)\n",
    "    \n",
    "    return total_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "# X_train=np.zeros((len(thresholded_wordlist),len(U_new)))\n",
    "X_train = []\n",
    "for sen in thresholded_wordlist:\n",
    "    X_train.append(sen2vec(sen))\n",
    "    #print(X_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train=np.zeros(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train[:999]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testDataGen():\n",
    "    wordlist_test = []\n",
    "    for i in tqdm(range(df_test.shape[0])):\n",
    "        wordlist_test.append(process_text(df_test['review'].iloc[i]))        \n",
    "    return wordlist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:14<00:00, 70.96it/s]\n"
     ]
    }
   ],
   "source": [
    "wordlist_test=testDataGen()\n",
    "X_test = []\n",
    "for sen in wordlist_test:\n",
    "    X_test.append(sen2vec(sen))\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test=np.concatenate((np.ones(500), np.zeros(500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[430,  70],\n",
       "       [204, 296]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5464, 50)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_new.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
